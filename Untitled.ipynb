{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "import xlsxwriter\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-fe15245abe2a>:10: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  eng_vars_Connection_columns = eng_vars_Connection_columns.set_index('connection_ru').T.to_dict('list')\n",
      "<ipython-input-3-fe15245abe2a>:15: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  eng_vars_Material_columns = eng_vars_Material_columns.set_index('material_ru').T.to_dict('list')\n",
      "<ipython-input-3-fe15245abe2a>:19: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  eng_vars_SeismoCat_columns = eng_vars_SeismoCat_columns.set_index('SeismoCat_ru').T.to_dict('list')\n"
     ]
    }
   ],
   "source": [
    "xls = pd.ExcelFile('vars_for_columns.xlsx')\n",
    "\n",
    "copy_columns = pd.read_excel(xls, 'copy_columns').replace('\\s+', ' ', regex=True).astype(str).apply(lambda x: x.str.lower())\n",
    "text_columns = pd.read_excel(xls, 'text_columns').replace('\\s+', ' ', regex=True).astype(str).apply(lambda x: x.str.lower())\n",
    "eng_vars_columns = pd.read_excel(xls, 'eng_vars_columns').replace('\\s+', ' ', regex=True).astype(str).apply(lambda x: x.str.lower())\n",
    "\n",
    "eng_vars_Connection_columns = pd.read_excel('english_vars_Connection.xlsx').replace('\\s+', ' ', regex=True)\n",
    "eng_vars_Connection_columns.connection_ru = eng_vars_Connection_columns.connection_ru.str.lower()\n",
    "eng_vars_Connection_columns = eng_vars_Connection_columns[['connection_ru','connection']]\n",
    "eng_vars_Connection_columns = eng_vars_Connection_columns.set_index('connection_ru').T.to_dict('list')\n",
    "\n",
    "eng_vars_Material_columns = pd.read_excel('english_vars_Material.xlsx').replace('\\s+', ' ', regex=True)\n",
    "eng_vars_Material_columns.material_ru = eng_vars_Material_columns.material_ru.str.lower()\n",
    "eng_vars_Material_columns = eng_vars_Material_columns[['material_ru','material']]\n",
    "eng_vars_Material_columns = eng_vars_Material_columns.set_index('material_ru').T.to_dict('list')\n",
    "\n",
    "eng_vars_SeismoCat_columns = pd.read_excel('english_vars_SeismoCat.xlsx').replace('\\s+', ' ', regex=True).astype(str).apply(lambda x: x.str.lower())\n",
    "eng_vars_SeismoCat_columns = eng_vars_SeismoCat_columns[['SeismoCat_ru','SeismoCat']]\n",
    "eng_vars_SeismoCat_columns = eng_vars_SeismoCat_columns.set_index('SeismoCat_ru').T.to_dict('list')\n",
    "\n",
    "varsDF = pd.concat([copy_columns,text_columns,eng_vars_columns],axis=1)\n",
    "\n",
    "varsNamesSet = set(copy_columns.stack().tolist())|set(text_columns.stack().tolist())|set(eng_vars_columns.stack().tolist())\n",
    "varsNamesSet.discard('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_xls = pd.ExcelFile('Text_dict_ver.2.xlsx')\n",
    "\n",
    "text_Type = pd.read_excel(text_xls, 'text_Type').replace('\\s+', ' ', regex=True).astype(str)\n",
    "text_Type['Тригер'] = text_Type['Тригер'].apply(lambda x: x.lower())\n",
    "text_Time = pd.read_excel(text_xls, 'Text_Time').replace('\\s+', ' ', regex=True).astype(str)\n",
    "text_Time['Тригер'] = text_Time['Тригер'].apply(lambda x: x.lower())\n",
    "text_NC = pd.read_excel(text_xls, 'Text_NC').replace('\\s+', ' ', regex=True).astype(str)\n",
    "text_NC['Тригер'] = text_NC['Тригер'].apply(lambda x: x.lower())\n",
    "text_Kv = pd.read_excel(text_xls, 'Text_Kv').replace('\\s+', ' ', regex=True).astype(str)\n",
    "text_Kv['Тригер'] = text_Kv['Тригер'].apply(lambda x: x.lower())\n",
    "text_Gmin = pd.read_excel(text_xls, 'Text_Gmin').replace('\\s+', ' ', regex=True).astype(str)\n",
    "text_Gmin['Тригер'] = text_Gmin['Тригер'].apply(lambda x: x.lower())\n",
    "text_Gmax = pd.read_excel(text_xls, 'Text_Gmax').replace('\\s+', ' ', regex=True).astype(str)\n",
    "text_Gmax['Тригер'] = text_Gmax['Тригер'].apply(lambda x: x.lower())\n",
    "text_Fluid = pd.read_excel(text_xls, 'Text_Fluid').replace('\\s+', ' ', regex=True).astype(str)\n",
    "text_Fluid['Тригер'] = text_Fluid['Тригер'].apply(lambda x: x.lower())\n",
    "text_Gmax = pd.read_excel(text_xls, 'Text_Gmax').replace('\\s+', ' ', regex=True).astype(str)\n",
    "text_Gmax['Тригер'] = text_Gmax['Тригер'].apply(lambda x: x.lower())\n",
    "text_Connection_pipeline = pd.read_excel(text_xls, 'Text_Connection_pipeline').replace('\\s+', ' ', regex=True).astype(str)\n",
    "text_Connection_pipeline['Тригер'] = text_Connection_pipeline['Тригер'].apply(lambda x: x.lower())\n",
    "text_Actuator_type = pd.read_excel(text_xls, 'Text_Actuator_type').replace('\\s+', ' ', regex=True).astype(str)\n",
    "text_Actuator_type['Тригер'] = text_Actuator_type['Тригер'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = pd.read_excel('ch/spec%20(8).xlsx').replace('\\s+', ' ', regex=True).astype(str).apply(lambda x: x.str.lower().replace('nan', np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropTopLeftRight(spec):\n",
    "\n",
    "    # finding elements from varsNamesSet\n",
    "    start_norm = time.time()\n",
    "    spec = spec.replace('\\s+', ' ', regex=True).astype(str).apply(lambda x: x.str.lower())\n",
    "    spec = spec.replace('nan', np.nan)\n",
    "    end_norm = time.time()\n",
    "#     print('Таблица нормализована за: {}'.format(end_norm-start_norm))\n",
    "    normTime = (end_norm-start_norm)\n",
    "\n",
    "    start_norm = time.time()\n",
    "    specTrueFalseMap = spec.isin(varsNamesSet).replace(False, np.nan)\n",
    "    if specTrueFalseMap.count(axis='columns').sum() == 0:\n",
    "#         print('Не удалось обработать файл')\n",
    "        return  pd.DataFrame()\n",
    "\n",
    "\n",
    "    # находим строку\n",
    "    heading_row = specTrueFalseMap.count(axis='columns').idxmax()+2\n",
    "    # находим левую границу\n",
    "    a = spec.iloc[specTrueFalseMap.count(axis='columns').idxmax()].isnull().replace(True,1)\n",
    "    if 'Unnamed: ' in a.idxmin():\n",
    "        heading_left_end = int(a.idxmin().split('Unnamed: ')[1])+1\n",
    "    else:\n",
    "        heading_left_end = a.index.get_loc(a.idxmin())+1\n",
    "    # находим правую границу\n",
    "    min_a = min(list(a))\n",
    "    len_a = len(list(a))\n",
    "    if [i for i, j in enumerate(list(a)) if j == min_a][-1] < len_a-1:\n",
    "        heading_right_end = [i for i, j in enumerate(list(a)) if j == min_a][-1]+1\n",
    "    else:\n",
    "        heading_right_end = len_a\n",
    "\n",
    "    RC_title = ((heading_row,heading_left_end),(heading_row,heading_right_end))\n",
    "\n",
    "    # находим строку с номерами столбцов\n",
    "    # в doesContainNumbersRow тупл с bool и координатами(тоже тупл)\n",
    "    doesContainNumbersRow = (False,())\n",
    "\n",
    "    try:\n",
    "        if int(spec.iloc[heading_row-1][1])+1 == int(spec.iloc[heading_row-1][2]):\n",
    "            doesContainNumbersRow = (True,((heading_row+1,heading_left_end),(heading_row+1,heading_right_end)))\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if not doesContainNumbersRow[0]:\n",
    "        try:\n",
    "            if int(spec.iloc[heading_row][1])+1 == int(spec.iloc[heading_row][2]):\n",
    "                doesContainNumbersRow = (True,((heading_row+2,heading_left_end),(heading_row+2,heading_right_end)))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # находим количество заголовков\n",
    "    numberOfTitleNames = (~spec.iloc[heading_row-2].isnull()).replace(True,1).sum()\n",
    "\n",
    "    # находим повторяющиеся заголовки и их количество\n",
    "    titelNames = Counter(spec.iloc[heading_row-2])\n",
    "    repeatedTitleNames = Counter(el for el in titelNames.elements() if titelNames[el] >= 2)\n",
    "#     print(repeatedTitleNames)\n",
    "    amountOFRepeatedTitleNames = sum(repeatedTitleNames.values())\n",
    "\n",
    "\n",
    "    # выясняем двойной ли заголовок\n",
    "    titleIsDoubled = False\n",
    "\n",
    "    if doesContainNumbersRow[0]:\n",
    "        if heading_row == doesContainNumbersRow[1][0][0]-2:\n",
    "            titleIsDoubled = True\n",
    "    else:\n",
    "        smallHead = list(spec.iloc[heading_row-1:].head(3).count(axis=1))\n",
    "        if smallHead[0] < sum(smallHead)/len(smallHead):\n",
    "            titleIsDoubled = True\n",
    "\n",
    "    # находим вторую (английскую) строку заголовков\n",
    "    secondTitle = (False,())\n",
    "\n",
    "    if titleIsDoubled:\n",
    "        try:\n",
    "            if (~spec.iloc[heading_row-4].isnull()).replace(True,1).sum() > 3:\n",
    "                secondTitle = (True, ((heading_row-2,heading_left_end),(heading_row-2,heading_right_end)))\n",
    "        except:\n",
    "            pass\n",
    "    else:\n",
    "        try:\n",
    "            if (~spec.iloc[heading_row-3].isnull()).replace(True,1).sum() > 3:\n",
    "                secondTitle = (True, ((heading_row-1,heading_left_end),(heading_row-1,heading_right_end)))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "    # # дропаем строку с номерами\n",
    "    # if doesContainNumbersRow[0]:\n",
    "    #     if doesContainNumbersRow[1][0][0] - heading_row == 1:\n",
    "    #         spec.drop(heading_row+1, inplace = True)\n",
    "    #     elif doesContainNumbersRow[1][0][0] - heading_row == 1:\n",
    "    #         spec.drop(heading_row, inplace = True)\n",
    "\n",
    "    spec = spec.iloc[specTrueFalseMap.count(axis='columns').idxmax():].dropna(how='all')\n",
    "    # print(spec)\n",
    "    listOfEmptyTitleFields = [i for i, j in spec.iloc[0].isnull().replace(False,np.nan).to_dict().items() if j == 1]\n",
    "    spec = spec.drop(columns=listOfEmptyTitleFields)\n",
    "    spec.columns = spec.iloc[0]\n",
    "    spec = spec.iloc[1:]\n",
    "    spec.reset_index(inplace = True,drop=True)\n",
    "    spec.columns.name = ''\n",
    "\n",
    "    end_norm = time.time()\n",
    "#     print('Чтение диапазона заголовков выполнено за: {}'.format(end_norm-start_norm))\n",
    "    titleReadingTime = end_norm-start_norm\n",
    "    return spec, RC_title, numberOfTitleNames, repeatedTitleNames, amountOFRepeatedTitleNames, titleIsDoubled, secondTitle,doesContainNumbersRow, titleReadingTime, normTime\n",
    "\n",
    "def renameColumnsNames(spec):\n",
    "    start_norm = time.time()\n",
    "    changedColumnsNames = []\n",
    "    changedColumnsNamesDict = {}\n",
    "\n",
    "    for i,col in enumerate(spec):\n",
    "        if col in varsNamesSet:\n",
    "            for j in varsDF:\n",
    "                if col in list(varsDF[j]):\n",
    "                    spec.rename(columns={col: j}, inplace=True)\n",
    "                    changedColumnsNames.append(j)\n",
    "                    try:\n",
    "                        if col in list(copy_columns[j]):\n",
    "                            changedColumnsNamesDict[col] = ((j,'copy_columns'))\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        if col in list(text_columns[j]):\n",
    "                            changedColumnsNamesDict[col] = ((j,'text_columns'))\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    try:\n",
    "                        if col in list(eng_vars_columns[j]):\n",
    "                            changedColumnsNamesDict[col] = ((j,'eng_vars_columns'))\n",
    "                    except:\n",
    "                        pass\n",
    "\n",
    "                    break\n",
    "        else:\n",
    "            changedColumnsNamesDict[col] = (('не обработан',''))\n",
    "\n",
    "\n",
    "\n",
    "    # numberOfColumnsAppearences = Counter(changedColumnsNames)\n",
    "    changedColumnsNames = list(set(changedColumnsNames))\n",
    "    end_norm = time.time()\n",
    "#     print('Обработка диапазона заголовков рабочей таблицы выполнена за: {}'.format(end_norm-start_norm))\n",
    "    return spec, changedColumnsNames, changedColumnsNamesDict\n",
    "\n",
    "def dropSpecsBottom(spec,titleIsDoubled,doesContainNumbersRow):\n",
    "    apearencesOfNanInRows = spec.isnull().sum(axis=1)\n",
    "\n",
    "    # h = Counter(apearencesOfNanInRows.head(int(len(apearencesOfNanInRows)/2))).most_common()\n",
    "\n",
    "    # listOfRowIndicesToDelete = list(apearencesOfNanInRows.loc[apearencesOfNanInRows > 1 + h[0][0]].index)\n",
    "\n",
    "\n",
    "    if doesContainNumbersRow[0] &  titleIsDoubled:\n",
    "        apearenceOfNanInRows = spec.iloc[2].isnull().sum()\n",
    "        # spec.drop([0,1], inplace=True)\n",
    "    elif doesContainNumbersRow[0] | titleIsDoubled:\n",
    "        apearenceOfNanInRows = spec.iloc[1].isnull().sum()\n",
    "        # spec.drop(0, inplace=True)\n",
    "    else:\n",
    "        apearenceOfNanInRows = spec.iloc[0].isnull().sum()\n",
    "\n",
    "    # apearenceOfNanInRows = spec.iloc[0].isnull().sum()\n",
    "    listOfRowIndicesToDelete = list(apearencesOfNanInRows.loc[apearencesOfNanInRows > 1 + apearenceOfNanInRows].index)\n",
    "\n",
    "    spec.drop(listOfRowIndicesToDelete,inplace=True)\n",
    "\n",
    "    if doesContainNumbersRow[0] &  titleIsDoubled:\n",
    "        # apearenceOfNanInRows = spec.iloc[2].isnull().sum()\n",
    "        try:\n",
    "            spec.drop([0,1], inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "    elif doesContainNumbersRow[0] | titleIsDoubled:\n",
    "        # apearenceOfNanInRows = spec.iloc[1].isnull().sum()\n",
    "        try:\n",
    "            spec.drop(0, inplace=True)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return spec\n",
    "\n",
    "def findSameColumnNames(spec):\n",
    "    # если есть одноименные столбцы мы их мержим. в astype можно указать другой тип данных\n",
    "    # к сожалению этот код меняет порядок в столбцов\n",
    "    def sjoin(x): return ';'.join(x[x.notnull()].astype(str))\n",
    "    spec = spec.groupby(level=0, axis=1).apply(lambda x: x.apply(sjoin, axis=1))\n",
    "    return spec\n",
    "\n",
    "def changingColumnsValues(spec):\n",
    "    columnsData = {}\n",
    "\n",
    "    for (columnName, columnData) in spec.iteritems():\n",
    "        columnsData[columnName] = {}\n",
    "        columnsData[columnName]['amountOfEmptyFields'] = spec[columnName].isnull().sum()\n",
    "        columnsData[columnName]['amountOfChangedFields'] = 0\n",
    "        columnsData[columnName]['amountOfUnchangedFields'] = len(columnData)\n",
    "        columnsData[columnName]['unchangedFields'] = set()\n",
    "\n",
    "        if columnName in list(copy_columns.columns):\n",
    "            columnsData[columnName]['amountOfChangedFields'] = columnData.astype(str).str.contains(',', regex=False).replace(np.nan, False).sum()\n",
    "            columnsData[columnName]['amountOfUnchangedFields'] = len(columnData) - columnsData[columnName]['amountOfChangedFields']\n",
    "            # print(spec[columnName].loc[~(spec[columnName].astype(str).str.contains(',', regex=False).replace(np.nan, True))])\n",
    "            # print(set(spec[columnName].loc[~(spec[columnName].astype(str).str.contains(',', regex=False).replace(np.nan, True))]))\n",
    "            columnsData[columnName]['unchangedFields'] = set(spec[columnName].loc[~(spec[columnName].astype(str).str.contains(',', regex=False).replace(np.nan, True))])\n",
    "            spec[columnName] = spec[columnName].astype(str).str.replace(',','.')\n",
    "\n",
    "        elif columnName in list(eng_vars_columns.columns):\n",
    "    #         for val in columnData:\n",
    "            for k in eng_vars_Connection_columns.keys():\n",
    "                columnsData[columnName]['unchangedFields'] = columnsData[columnName]['unchangedFields'].union(set(spec[columnName].loc[~spec[columnName].astype(str).str.contains(k, regex=False).replace(np.nan, True)]))\n",
    "                columnsData[columnName]['amountOfChangedFields'] += len(spec[columnName].loc[spec[columnName].astype(str).str.contains(k, regex=False).replace(np.nan, True)])\n",
    "                columnsData[columnName]['amountOfUnchangedFields'] -= len(spec[columnName].loc[spec[columnName].astype(str).str.contains(k, regex=False).replace(np.nan, True)])\n",
    "                spec[columnName] = spec[columnName].astype(str).str.replace(k,str(eng_vars_Connection_columns[k][0]),regex=False)\n",
    "            for k in eng_vars_Material_columns.keys():\n",
    "                columnsData[columnName]['unchangedFields'] = columnsData[columnName]['unchangedFields'].union(set(spec[columnName].loc[~spec[columnName].astype(str).str.contains(k, regex=False).replace(np.nan, True)]))\n",
    "                columnsData[columnName]['amountOfChangedFields'] += len(spec[columnName].loc[spec[columnName].astype(str).str.contains(k, regex=False).replace(np.nan, True)])\n",
    "                columnsData[columnName]['amountOfUnchangedFields'] -= len(spec[columnName].loc[spec[columnName].astype(str).str.contains(k, regex=False).replace(np.nan, True)])\n",
    "                spec[columnName] = spec[columnName].astype(str).str.replace(k,str(eng_vars_Material_columns[k][0]),regex=False)\n",
    "            for k in eng_vars_SeismoCat_columns.keys():\n",
    "                columnsData[columnName]['unchangedFields'] = columnsData[columnName]['unchangedFields'].union(set(spec[columnName].loc[~spec[columnName].astype(str).str.contains(k, regex=False).replace(np.nan, True)]))\n",
    "                columnsData[columnName]['amountOfChangedFields'] += len(spec[columnName].loc[spec[columnName].astype(str).str.contains(k, regex=False).replace(np.nan, True)])\n",
    "                columnsData[columnName]['amountOfUnchangedFields'] -= len(spec[columnName].loc[spec[columnName].astype(str).str.contains(k, regex=False).replace(np.nan, True)])\n",
    "                spec[columnName] = spec[columnName].astype(str).str.replace(k,str(eng_vars_SeismoCat_columns[k][0]),regex=False)\n",
    "\n",
    "            columnsData[columnName]['unchangedFields'] = list(set(columnsData[columnName]['unchangedFields']))\n",
    "    # text_Type\n",
    "    if 'Type' in spec.columns:\n",
    "        if not 'Bellow' in spec.columns:\n",
    "            spec['Bellow'] = ''\n",
    "        if not 'Actuator type' in spec.columns:\n",
    "            spec['Actuator type'] = ''\n",
    "        if not 'RPI' in spec.columns:\n",
    "            spec['RPI'] = ''\n",
    "        if not 'DC' in spec.columns:\n",
    "            spec['DC'] = ''\n",
    "        if not 'Fluid' in spec.columns:\n",
    "            spec['Fluid'] = ''\n",
    "        if not 'Connection' in spec.columns:\n",
    "            spec['Connection'] = ''\n",
    "        if not 'Material' in spec.columns:\n",
    "            spec['Material'] = ''\n",
    "        for index, item in spec['Type'].items():\n",
    "\n",
    "            triggersInItem = text_Type.loc[text_Type['Тригер'].apply(lambda x: x in item)]\n",
    "            triggersInItem = triggersInItem.replace('nan','')\n",
    "            triggersInItem = triggersInItem.loc[~(triggersInItem['Weight']=='')]\n",
    "            triggersInItem['Weight'] = triggersInItem['Weight'].apply(lambda x: float(x))\n",
    "            valuesfForTypeField = ''\n",
    "            valuesForActuatorType = ''\n",
    "            valuesForBellow = ''\n",
    "            valuesForConnection = ''\n",
    "            valuesForMaterial = ''\n",
    "            valuesForRPI = ''\n",
    "            valuesForFluid = ''\n",
    "            valuesForDC = ''\n",
    "            weight = -1\n",
    "\n",
    "            for i, val in triggersInItem.iterrows():\n",
    "\n",
    "                if (valuesForBellow == '') & (val['Bellow'] != ''):\n",
    "                    valuesForBellow = val['Bellow']\n",
    "\n",
    "                if (valuesForRPI == '') & (val['RPI'] != ''):\n",
    "                    valuesForRPI = val['RPI']\n",
    "\n",
    "                if (valuesForDC == '') & (val['DC'] != ''):\n",
    "                    valuesForDC = val['DC']\n",
    "\n",
    "                if not val['Actuator type'] in valuesForActuatorType:\n",
    "                    if weight == -1:\n",
    "                        valuesForActuatorType += val['Actuator type']\n",
    "                    else:\n",
    "                        valuesForActuatorType += ', ' + val['Actuator type']\n",
    "\n",
    "\n",
    "                if not val['Connection'] in valuesForConnection:\n",
    "                    if weight == -1 :\n",
    "                        valuesForConnection += val['Connection']\n",
    "                    else:\n",
    "                        valuesForConnection += ', ' + val['Connection']\n",
    "\n",
    "                if not val['Material'] in valuesForMaterial:\n",
    "                    if weight == -1 :\n",
    "                        valuesForMaterial += val['Material']\n",
    "                    else:\n",
    "                        valuesForMaterial += ', ' + val['Material']\n",
    "\n",
    "                if not val['Fluid'] in valuesForFluid:\n",
    "                    if weight == -1 :\n",
    "                        valuesForFluid += val['Fluid']\n",
    "                    else:\n",
    "                        valuesForFluid += ', ' + val['Fluid']\n",
    "\n",
    "                if val['Weight'] >= weight:\n",
    "                    if weight == -1:\n",
    "                        valuesfForTypeField += val['Type']\n",
    "                    else:\n",
    "                        valuesfForTypeField += ', ' + val['Type']\n",
    "                    weight = val['Weight']\n",
    "\n",
    "            if valuesfForTypeField != '':\n",
    "                spec['Type'].loc[index] = valuesfForTypeField\n",
    "            spec['Bellow'].loc[index] = valuesForBellow\n",
    "            spec['RPI'].loc[index] = valuesForRPI\n",
    "\n",
    "            if spec['DC'].loc[index] == '':\n",
    "                spec['DC'].loc[index] = valuesForDC\n",
    "            else:\n",
    "                if valuesForDC != '':\n",
    "                    spec['DC'].loc[index] += ', ' + valuesForDC\n",
    "\n",
    "\n",
    "            if spec['Connection'].loc[index] == '':\n",
    "                spec['Connection'].loc[index] = valuesForConnection\n",
    "            else:\n",
    "                if valuesForConnection != '':\n",
    "                    spec['Connection'].loc[index] += ', ' + valuesForConnection\n",
    "\n",
    "\n",
    "            if spec['Material'].loc[index] == '':\n",
    "                spec['Material'].loc[index] = valuesForMaterial\n",
    "            else:\n",
    "                if valuesForMaterial != '':\n",
    "                    spec['Material'].loc[index] += ', ' + valuesForMaterial\n",
    "\n",
    "\n",
    "            if spec['Fluid'].loc[index] == '':\n",
    "                spec['Fluid'].loc[index] = valuesForFluid\n",
    "            else:\n",
    "                if valuesForFluid != '':\n",
    "                    spec['Fluid'].loc[index] += ', ' + valuesForFluid\n",
    "\n",
    "\n",
    "            if spec['Actuator type'].loc[index] == '':\n",
    "                spec['Actuator type'].loc[index] = valuesForActuatorType\n",
    "            else:\n",
    "                if valuesForActuatorType != '':\n",
    "                    spec['Actuator type'].loc[index] += ', ' + valuesForActuatorType\n",
    "\n",
    "    # text_Time\n",
    "    if 'Time' in spec.columns:\n",
    "        for index, item in spec['Time'].items():\n",
    "            spec['Time'].loc[index] = re.sub(\"[^0-9]\", \"\", str(spec['Time'].loc[index]))\n",
    "\n",
    "    # Text_NC\n",
    "    if 'NC' in spec.columns:\n",
    "        if not 'GroupNC' in spec.columns:\n",
    "            spec['GroupNC'] = ''\n",
    "        if not 'Dostup' in spec.columns:\n",
    "            spec['Dostup'] = ''\n",
    "        if not 'Pletter' in spec.columns:\n",
    "            spec['Pletter'] = ''\n",
    "        if not 'SeismoCat' in spec.columns:\n",
    "            spec['SeismoCat'] = ''\n",
    "        for index, item in spec['NC'].items():\n",
    "            triggersInItem = text_NC.loc[text_NC['Тригер'].str.contains(item)]\n",
    "            triggersInItem = triggersInItem.replace('nan','')\n",
    "            triggersInItem['Weight'] = triggersInItem['Weight'].apply(lambda x: float(x))\n",
    "            NC_values = ''\n",
    "            GroupNC_values = ''\n",
    "            Dostup_values = ''\n",
    "            Pletter_values = ''\n",
    "            SeismoCat_values = ''\n",
    "\n",
    "            # на случай предпоследнего варианта с весом 4000\n",
    "            if len(re.sub(\"[^0-9]\", \"\", item)) == len(item):\n",
    "                NC_values = item\n",
    "                continue\n",
    "\n",
    "            # для основной массы\n",
    "            for i, val in triggersInItem.iterrows():\n",
    "                if NC_values == '':\n",
    "                    NC_values = val['NC']\n",
    "                else:\n",
    "                    NC_values += ', ' + val['NC']\n",
    "\n",
    "                if GroupNC_values == '':\n",
    "                    GroupNC_values = val['GroupNC']\n",
    "                else:\n",
    "                    GroupNC_values += ', ' + val['GroupNC']\n",
    "\n",
    "                if Dostup_values == '':\n",
    "                    Dostup_values = val['Dostup']\n",
    "                else:\n",
    "                    Dostup_values += ', ' + val['Dostup']\n",
    "\n",
    "                if Pletter_values == '':\n",
    "                    Pletter_values = val['Pletter']\n",
    "                else:\n",
    "                    Pletter_values += ', ' + val['Pletter']\n",
    "\n",
    "                if SeismoCat_values == '':\n",
    "                    SeismoCat_values = val['SeismoCat']\n",
    "                else:\n",
    "                    SeismoCat_values += ', ' + val['SeismoCat']\n",
    "\n",
    "\n",
    "            # для последнего варианта с весом 4000\n",
    "            for el in re.findall(r'[0-9]+/[^0-9]+', item):\n",
    "                NC_values += ', ' + el\n",
    "\n",
    "            # для вариантов с весом 3000\n",
    "            for el in re.findall(r'[^0-9], i', item):\n",
    "                if SeismoCat_values == '':\n",
    "                    SeismoCat_values = '1'\n",
    "                else:\n",
    "                    SeismoCat_values += ', 1'\n",
    "\n",
    "            for el in re.findall(r'[^0-9], ii', item):\n",
    "                if SeismoCat_values == '':\n",
    "                    SeismoCat_values = '2'\n",
    "                else:\n",
    "                    SeismoCat_values += ', 2'\n",
    "\n",
    "            for el in re.findall(r'[^0-9], iii', item):\n",
    "                if SeismoCat_values == '':\n",
    "                    SeismoCat_values = '3'\n",
    "                else:\n",
    "                    SeismoCat_values += ', 3'\n",
    "\n",
    "            for el in re.findall(r'[^0-9]/i', item):\n",
    "                if SeismoCat_values == '':\n",
    "                    SeismoCat_values = '1'\n",
    "                else:\n",
    "                    SeismoCat_values += ', 1'\n",
    "\n",
    "            for el in re.findall(r'[^0-9]/ii', item):\n",
    "                if SeismoCat_values == '':\n",
    "                    SeismoCat_values = '2'\n",
    "                else:\n",
    "                    SeismoCat_values += ', 2'\n",
    "\n",
    "            for el in re.findall(r'[^0-9]/iii', item):\n",
    "                if SeismoCat_values == '':\n",
    "                    SeismoCat_values = '3'\n",
    "                else:\n",
    "                    SeismoCat_values += ', 3'\n",
    "\n",
    "            if NC_values != '':\n",
    "                spec['NC'].loc[index] = NC_values\n",
    "\n",
    "            if spec['GroupNC'].loc[index] == '':\n",
    "                spec['GroupNC'].loc[index] = GroupNC_values\n",
    "            else:\n",
    "                if GroupNC_values != '':\n",
    "                    spec['GroupNC'].loc[index] += ', ' + GroupNC_values\n",
    "\n",
    "            if spec['Dostup'].loc[index] == '':\n",
    "                spec['Dostup'].loc[index] = Dostup_values\n",
    "            else:\n",
    "                if Dostup_values != '':\n",
    "                    spec['Dostup'].loc[index] += ', ' + Dostup_values\n",
    "\n",
    "            if spec['Pletter'].loc[index] == '':\n",
    "                spec['Pletter'].loc[index] = Pletter_values\n",
    "            else:\n",
    "                if Pletter_values != '':\n",
    "                    spec['Pletter'].loc[index] += ', ' + Pletter_values\n",
    "\n",
    "            if spec['SeismoCat'].loc[index] == '':\n",
    "                spec['SeismoCat'].loc[index] = SeismoCat_values\n",
    "            else:\n",
    "                if SeismoCat_values != '':\n",
    "                    spec['SeismoCat'].loc[index] += ', ' + SeismoCat_values\n",
    "\n",
    "    # text_Kv\n",
    "    if 'Kv' in spec.columns:\n",
    "        if not 'F' in spec.columns:\n",
    "            spec['F'] = ''\n",
    "        for index, item in spec['Kv'].items():\n",
    "            Kv_values = ''\n",
    "            F_values = ''\n",
    "            el = ''\n",
    "\n",
    "            try:\n",
    "                el = re.findall(r'kv=[0-9]+ fmin=[0-9]+ см2', item)[0]\n",
    "                numbersFromElement = re.findall(r'[0-9]+',el)\n",
    "                Kv_values = numbersFromElement[0]\n",
    "                F_values = numbersFromElement[1]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            if len(re.sub(\"[^0-9]\", \"\", str(item))) == len(str(item)):\n",
    "                Kv_values = item\n",
    "\n",
    "            if Kv_values != '':\n",
    "                spec['Kv'].loc[index] = Kv_values\n",
    "                spec['F'].loc[index] = F_values\n",
    "\n",
    "    # text_Gmin\n",
    "    if 'Gmin under ∆Pmax' in spec.columns:\n",
    "        for index, item in spec['Gmin under ∆Pmax'].items():\n",
    "            Gmin_value = ''\n",
    "            el = ''\n",
    "            try:\n",
    "                el = re.findall(r'[0-9]+ нм3/ч', item)[0]\n",
    "                Gmin_value = re.findall(r'[0-9]+',el)[0]\n",
    "            except: pass\n",
    "\n",
    "            if len(re.sub(\"[^0-9]\", \"\", item)) == len(item):\n",
    "                Gmin_value = item\n",
    "\n",
    "            if Gmin_value != '':\n",
    "                spec['Gmin under ∆Pmax'].loc[index] = Gmin_value\n",
    "\n",
    "    # text_Gmax\n",
    "    if 'Gmax under ∆Pmin' in spec.columns:\n",
    "        for index, item in spec['Gmax under ∆Pmin'].items():\n",
    "            Gmax_value = ''\n",
    "            el = ''\n",
    "            try:\n",
    "                el = re.findall(r'[0-9]+ нм3/ч', item)[0]\n",
    "                Gmax_value = re.findall(r'[0-9]+',el)[0]\n",
    "            except: pass\n",
    "\n",
    "            if len(re.sub(\"[^0-9]\", \"\", item)) == len(item):\n",
    "                Gmax_value = item\n",
    "\n",
    "            if Gmax_value != '':\n",
    "                spec['Gmax under ∆Pmin'].loc[index] = Gmax_value\n",
    "\n",
    "    # text_Fluid\n",
    "    if 'Fluid' in spec.columns:\n",
    "        for index, item in spec['Fluid'].items():\n",
    "            triggersInItem = text_Fluid.loc[text_Fluid['Тригер'].str.contains(item)]\n",
    "            if len(triggersInItem) > 0:\n",
    "                spec['Fluid'].loc[index] = ', '.join(list(triggersInItem['Fluid'].astype(str)))\n",
    "\n",
    "    # Text_Connection_pipeline\n",
    "    if 'Connection_pipeline' in spec.columns:\n",
    "        for index, item in spec['Connection_pipeline'].items():\n",
    "            Connection_pipeline_value = ''\n",
    "            el = ''\n",
    "            try:\n",
    "                el = re.findall(r'[0-9]+x[0-9]+', item)[0]\n",
    "                Connection_pipeline_value = el\n",
    "            except: pass\n",
    "\n",
    "\n",
    "            if Connection_pipeline_value != '':\n",
    "                spec['Connection_pipeline'].loc[index] = Connection_pipeline_value\n",
    "\n",
    "    # text_Actuator_type\n",
    "    if 'Actuator type' in spec.columns:\n",
    "        if not 'RPI' in spec.columns:\n",
    "            spec['RPI'] = ''\n",
    "        if not 'under containment' in spec.columns:\n",
    "            spec['under containment'] = ''\n",
    "        for index, item in spec['Actuator type'].items():\n",
    "            Actuator_type_values = ''\n",
    "            RPI_values = ''\n",
    "            under_containment_values = ''\n",
    "            triggersInItem = text_Actuator_type.loc[text_Actuator_type['Тригер'].str.contains(item)]\n",
    "            triggersInItem = triggersInItem.replace('nan','')\n",
    "            triggersInItem['Weight'] = triggersInItem['Weight'].apply(lambda x: float(x))\n",
    "\n",
    "            if len(triggersInItem) > 0:\n",
    "                triggersWithBigWeight = triggersInItem.loc[triggersInItem['Weight'] == triggersInItem['Weight'].iloc[0]]\n",
    "            else: continue\n",
    "\n",
    "            Actuator_type_values = ', '.join(set(triggersWithBigWeight['Actuator type']))\n",
    "\n",
    "            RPI_values = set(triggersInItem['RPI'])\n",
    "            RPI_values.discard('')\n",
    "            under_containment_values = set(triggersInItem['under containment'])\n",
    "            under_containment_values.discard('')\n",
    "            if Actuator_type_values != '':\n",
    "                spec['Actuator type'].loc[index] = Actuator_type_values\n",
    "                if len(under_containment_values) > 0:\n",
    "                    under_containment_value = next(iter(under_containment_values))\n",
    "                    spec['under containment'].loc[index] = under_containment_value\n",
    "                if len(RPI_values) > 0:\n",
    "                    RPI_value = next(iter(RPI_values))\n",
    "                    spec['RPI'].loc[index] = RPI_value\n",
    "\n",
    "\n",
    "    return spec, columnsData\n",
    "\n",
    "def findingTable(spec):\n",
    "    stats = {}\n",
    "    # droppig unwanted columns and rows from top and left\n",
    "    spec, stats['RC_title'], stats['numberOfTitleNames'], stats['repeatedTitleNames'], stats['amountOFRepeatedTitleNames'], stats['titleIsDoubled'], stats['secondTitle'],stats['doesContainNumbersRow'],stats['titleReadingTime'], stats['normTime'] = dropTopLeftRight(spec)\n",
    "\n",
    "    # changing columns names\n",
    "    spec, changedColumnsNames, stats['changedColumnsNamesDict'] = renameColumnsNames(spec)\n",
    "    stats['changedColumnsNamesAmount'] = len(changedColumnsNames)\n",
    "\n",
    "\n",
    "    # finding the bottom of spec\n",
    "    start_read = time.time()\n",
    "    spec = dropSpecsBottom(spec,stats['titleIsDoubled'],stats['doesContainNumbersRow'])\n",
    "\n",
    "    # находим диапазон значений\n",
    "    stats['RC_rows'] = ( ( stats['RC_title'][0][0] + 1 , stats['RC_title'][0][1] ) , ( stats['RC_title'][0][0] + 1 , stats['RC_title'][1][1] ) )\n",
    "\n",
    "    if stats['doesContainNumbersRow'][0] &  stats['titleIsDoubled']:\n",
    "        stats['RC_rows'] = ((stats['RC_title'][0][0]+3,stats['RC_title'][0][1]),(spec.tail(1).index[0] + stats['RC_title'][0][0] + 1,stats['RC_title'][1][1]))\n",
    "    elif stats['doesContainNumbersRow'][0] | stats['titleIsDoubled']:\n",
    "        if stats['doesContainNumbersRow'][0]:\n",
    "            stats['RC_rows'] = ((stats['RC_title'][0][0]+2,stats['RC_title'][0][1]),(spec.tail(1).index[0] + stats['RC_title'][0][0] + 1,stats['RC_title'][1][1]))\n",
    "        else:\n",
    "            stats['RC_rows'] = ((stats['RC_title'][0][0]+2,stats['RC_title'][0][1]),(spec.tail(1).index[0] + stats['RC_title'][0][0] + 1,stats['RC_title'][1][1]))\n",
    "\n",
    "\n",
    "    stats['amountOfRows'] = stats['RC_rows'][1][0] - stats['RC_rows'][0][0] + 1\n",
    "\n",
    "    end_read = time.time()\n",
    "#     print('Чтение диапазона характеристик выполнено за: {}'.format(end_read-start_read))\n",
    "    stats['chReadingTime'] = end_read-start_read\n",
    "\n",
    "    spec = spec.fillna('REPLACEMENT')\n",
    "\n",
    "    # find and merge columns with same name\n",
    "    spec = findSameColumnNames(spec)\n",
    "    copiesFreqDF = pd.DataFrame(spec.value_counts(subset=changedColumnsNames))\n",
    "\n",
    "    spec['countClones'] = 0\n",
    "    for i,r in enumerate(spec.iterrows()):\n",
    "        spec['countClones'].iloc[i] = copiesFreqDF.loc[tuple(r[1].loc[changedColumnsNames])][0]\n",
    "        copiesFreqDF.loc[tuple(r[1].loc[changedColumnsNames])][0] = 0\n",
    "\n",
    "    spec = spec.loc[spec['countClones']!=0]\n",
    "\n",
    "    if 'DN' in spec.columns:\n",
    "        spec = spec.sort_values(by=['DN'])\n",
    "\n",
    "    spec = spec.replace('REPLACEMENT', np.nan)\n",
    "\n",
    "    spec , stats['columnsStats']= changingColumnsValues(spec)\n",
    "    return spec, stats\n",
    "\n",
    "\n",
    "def saveSpec(PATH, stats, PATH_TO_SAVE=''):\n",
    "\n",
    "    # Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "    writer = pd.ExcelWriter(PATH_TO_SAVE + 'table_'+PATH.split('/')[-1], engine='xlsxwriter')\n",
    "\n",
    "    # Convert the dataframe to an XlsxWriter Excel object.\n",
    "    spec.sort_index(inplace = True)\n",
    "    spec.to_excel(writer, sheet_name='Sheet1')\n",
    "\n",
    "    # Get the xlsxwriter workbook and worksheet objects.\n",
    "    workbook  = writer.book\n",
    "    worksheet1 = writer.sheets['Sheet1']\n",
    "    worksheet2 = workbook.add_worksheet()\n",
    "    worksheet3 = workbook.add_worksheet()\n",
    "\n",
    "    # worksheet2.write('A2', pd.DataFrame.from_dict(stats))\n",
    "    dictForFirstTaskKeys = {\n",
    "        'RC_title': 'RC:RC для строки заголовков',\n",
    "        'numberOfTitleNames':'количество заголовков',\n",
    "        'repeatedTitleNames':'повторяющиеся заголовки',\n",
    "        'amountOFRepeatedTitleNames':'количество повторяющихся заголовков',\n",
    "        'titleIsDoubled':'двойной заголовок',\n",
    "        'secondTitle':'второй (английский ) заголовок',\n",
    "        'doesContainNumbersRow':'содержит строку с номерами столбцов',\n",
    "        'titleReadingTime':'вреся на чтение диапазона заголовков',\n",
    "        'normTime':'время на нормализацию',\n",
    "        'changedColumnsNamesDict':'заменен или нет заголовок',\n",
    "        'changedColumnsNamesAmount':'замененных заголовков',\n",
    "        'RC_rows':'RC:RC диапазона характеристик',\n",
    "        'chReadingTime':'время на чтение диапазона характеристик',\n",
    "        'amountOfRows':'количество строк в диапазоне характеристик'\n",
    "    }\n",
    "\n",
    "\n",
    "    row = 2\n",
    "    for key in stats:\n",
    "        if key == 'columnsStats':\n",
    "            continue\n",
    "        worksheet2.write('A' + str(row), dictForFirstTaskKeys[key])\n",
    "        worksheet2.write('B' + str(row), str(stats[key]))\n",
    "        row = row + 1\n",
    "\n",
    "\n",
    "    col = 2\n",
    "\n",
    "    listOfUnchangedValues = set()\n",
    "\n",
    "    def isNaN(num):\n",
    "        return num != num\n",
    "    for key in stats['columnsStats']:\n",
    "        worksheet3.write(2, col, key)\n",
    "        worksheet3.write(3, col, 'amountOfEmptyFields')\n",
    "        worksheet3.write(3, col+1, stats['columnsStats'][key]['amountOfEmptyFields'])\n",
    "        worksheet3.write(4, col, 'amountOfChangedFields')\n",
    "        worksheet3.write(4, col+1, stats['columnsStats'][key]['amountOfChangedFields'])\n",
    "        worksheet3.write(5, col, 'amountOfUnchangedFields')\n",
    "        worksheet3.write(5, col+1, stats['columnsStats'][key]['amountOfUnchangedFields'])\n",
    "        worksheet3.write(6, col, 'unchangedFields')\n",
    "        k = 0\n",
    "        listOfUnchangedValues = listOfUnchangedValues.union(set(stats['columnsStats'][key]['unchangedFields']))\n",
    "        for el in set(stats['columnsStats'][key]['unchangedFields']):\n",
    "            if not isNaN(el):\n",
    "                worksheet3.write(6+k, col+1,el)\n",
    "                k += 1\n",
    "\n",
    "        col += 2\n",
    "\n",
    "    # listOfUnchangedValues = list(set(listOfUnchangedValues))\n",
    "    # print(listOfUnchangedValues)\n",
    "\n",
    "    # Add a format. Light red fill with dark red text.\n",
    "    format1 = workbook.add_format({'bg_color': '#FFC7CE',\n",
    "                                   'font_color': '#9C0006'})\n",
    "\n",
    "    # Add a header format.\n",
    "    copy_columns_header_cell_format = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'text_wrap': True,\n",
    "        'valign': 'top',\n",
    "        'fg_color': '#D7E4BC',\n",
    "        'border': 1})\n",
    "\n",
    "    text_columns_header_cell_format = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'text_wrap': True,\n",
    "        'valign': 'top',\n",
    "        'fg_color': '#D7E55В',\n",
    "        'border': 1})\n",
    "\n",
    "    eng_vars_columns_header_cell_format = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'text_wrap': True,\n",
    "        'valign': 'top',\n",
    "        'fg_color': '#D7EССС',\n",
    "        'border': 1})\n",
    "\n",
    "    usuals_columns_header_cell_format = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'text_wrap': True,\n",
    "        'valign': 'top',\n",
    "        'fg_color': '#FFFFFF',\n",
    "        'border': 1})\n",
    "\n",
    "    unrecognized_cell_format = workbook.add_format({\n",
    "        'bold': True,\n",
    "        'text_wrap': True,\n",
    "        'valign': 'top',\n",
    "        'fg_color': '#444444',\n",
    "        'border': 1})\n",
    "\n",
    "\n",
    "    # Write the column headers with the defined format.\n",
    "    for col_num, value in enumerate(spec.columns.values):\n",
    "        if value in set(copy_columns.columns):\n",
    "            worksheet1.write(0, col_num + 1, value, copy_columns_header_cell_format)\n",
    "        elif value in set(text_columns.columns):\n",
    "            worksheet1.write(0, col_num + 1, value, text_columns_header_cell_format)\n",
    "        elif value in set(eng_vars_columns.columns):\n",
    "            worksheet1.write(0, col_num + 1, value, eng_vars_columns_header_cell_format)\n",
    "        else:\n",
    "            worksheet1.write(0, col_num + 1, value, usuals_columns_header_cell_format)\n",
    "\n",
    "    for (columnName, columnData) in spec.iteritems():\n",
    "        if not columnName in stats['changedColumnsNamesDict'].keys():\n",
    "\n",
    "            # print(list(columnData.loc[columnData.isin(listOfUnchangedValues)].index))\n",
    "            indicesList = list(columnData.loc[columnData.isin(listOfUnchangedValues)].index)\n",
    "            # if columnName == 'KKS' :\n",
    "                # print('{}: {}'.format(columnName,columnData.isin(listOfUnchangedValues)))\n",
    "            indicesList.sort()\n",
    "            # print(indicesList)\n",
    "            for value in indicesList:\n",
    "\n",
    "                # print(spec[columnName][spec.index.get_loc(value)])\n",
    "                # print(isNaN(spec[columnName][spec.index.get_loc(value)]))\n",
    "                if not isNaN(spec.loc[value][columnName]):\n",
    "                    # print(spec[columnName][spec.index.get_loc(value)])\n",
    "                    worksheet1.write(value, spec.columns.get_loc(columnName)+1, spec.loc[value][columnName], unrecognized_cell_format)\n",
    "\n",
    "    # print(listOfUnchangedValues)\n",
    "    # Close the Pandas Excel writer and output the Excel file.\n",
    "    writer.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec, stats = findingTable(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Gmin under ∆Pmax'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/miniconda3/envs/sls_env/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Gmin under ∆Pmax'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5ba93bc75211>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Gmin under ∆Pmax'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Gmin under ∆Pmax'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/miniconda3/envs/sls_env/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2902\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2903\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2904\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda3/envs/sls_env/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2895\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Gmin under ∆Pmax'"
     ]
    }
   ],
   "source": [
    "spec['Gmin under ∆Pmax'].loc[spec['Gmin under ∆Pmax'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actuator info</th>\n",
       "      <th>Actuator type</th>\n",
       "      <th>Connection</th>\n",
       "      <th>DN</th>\n",
       "      <th>Fluid</th>\n",
       "      <th>KKS</th>\n",
       "      <th>Kv</th>\n",
       "      <th>Material</th>\n",
       "      <th>NC</th>\n",
       "      <th>Nnom</th>\n",
       "      <th>...</th>\n",
       "      <th>№ п/п</th>\n",
       "      <th>countClones</th>\n",
       "      <th>Bellow</th>\n",
       "      <th>RPI</th>\n",
       "      <th>DC</th>\n",
       "      <th>GroupNC</th>\n",
       "      <th>Dostup</th>\n",
       "      <th>Pletter</th>\n",
       "      <th>F</th>\n",
       "      <th>under containment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>BS</td>\n",
       "      <td>BW</td>\n",
       "      <td>100</td>\n",
       "      <td>р-р для хим пром пг</td>\n",
       "      <td>10lfg42aa002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SS</td>\n",
       "      <td>2</td>\n",
       "      <td>4.25</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td>II</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>NaN</td>\n",
       "      <td>BS</td>\n",
       "      <td>BW</td>\n",
       "      <td>100</td>\n",
       "      <td>р-р для хим пром пг</td>\n",
       "      <td>20lfg42aa001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SS</td>\n",
       "      <td>2</td>\n",
       "      <td>4.25</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td>II</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>NaN</td>\n",
       "      <td>BS</td>\n",
       "      <td>BW</td>\n",
       "      <td>100</td>\n",
       "      <td>р-р для хим пром пг</td>\n",
       "      <td>20lfg44aa001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SS</td>\n",
       "      <td>2</td>\n",
       "      <td>4.25</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td>II</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>NaN</td>\n",
       "      <td>BS</td>\n",
       "      <td>BW</td>\n",
       "      <td>100</td>\n",
       "      <td>р-р для хим пром пг</td>\n",
       "      <td>20lfg42aa002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SS</td>\n",
       "      <td>2</td>\n",
       "      <td>4.25</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td>II</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>NaN</td>\n",
       "      <td>BS</td>\n",
       "      <td>BW</td>\n",
       "      <td>100</td>\n",
       "      <td>р-р для хим пром пг</td>\n",
       "      <td>20lfg44aa002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SS</td>\n",
       "      <td>2</td>\n",
       "      <td>4.25</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>B</td>\n",
       "      <td>II</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>NaN</td>\n",
       "      <td>BS</td>\n",
       "      <td>BW</td>\n",
       "      <td>800</td>\n",
       "      <td>Steam</td>\n",
       "      <td>20lba50aa001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alloy steel</td>\n",
       "      <td>3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>...</td>\n",
       "      <td>117</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td>III</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>NaN</td>\n",
       "      <td>BS</td>\n",
       "      <td>BW</td>\n",
       "      <td>800</td>\n",
       "      <td>Steam</td>\n",
       "      <td>20lba70aa001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alloy steel</td>\n",
       "      <td>3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>...</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td>III</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>NaN</td>\n",
       "      <td>BS</td>\n",
       "      <td>BW</td>\n",
       "      <td>800</td>\n",
       "      <td>Steam</td>\n",
       "      <td>20lba60aa001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alloy steel</td>\n",
       "      <td>3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td>III</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>NaN</td>\n",
       "      <td>BS</td>\n",
       "      <td>BW</td>\n",
       "      <td>800</td>\n",
       "      <td>Steam</td>\n",
       "      <td>20lba80aa001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alloy steel</td>\n",
       "      <td>3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td>III</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>BS</td>\n",
       "      <td>BW</td>\n",
       "      <td>800</td>\n",
       "      <td>Steam</td>\n",
       "      <td>10lba60aa001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alloy steel</td>\n",
       "      <td>3</td>\n",
       "      <td>9.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>C</td>\n",
       "      <td>III</td>\n",
       "      <td>a</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actuator info Actuator type Connection   DN                Fluid  \\\n",
       "15             NaN            BS         BW  100  р-р для хим пром пг   \n",
       "77             NaN            BS         BW  100  р-р для хим пром пг   \n",
       "76             NaN            BS         BW  100  р-р для хим пром пг   \n",
       "75             NaN            BS         BW  100  р-р для хим пром пг   \n",
       "73             NaN            BS         BW  100  р-р для хим пром пг   \n",
       "..             ...           ...        ...  ...                  ...   \n",
       "117            NaN            BS         BW  800                Steam   \n",
       "120            NaN            BS         BW  800                Steam   \n",
       "119            NaN            BS         BW  800                Steam   \n",
       "121            NaN            BS         BW  800                Steam   \n",
       "1              NaN            BS         BW  800                Steam   \n",
       "\n",
       "              KKS  Kv     Material NC  Nnom  ... № п/п countClones Bellow RPI  \\\n",
       "15   10lfg42aa002 NaN           SS  2  4.25  ...    15           1              \n",
       "77   20lfg42aa001 NaN           SS  2  4.25  ...    77           1              \n",
       "76   20lfg44aa001 NaN           SS  2  4.25  ...    76           1              \n",
       "75   20lfg42aa002 NaN           SS  2  4.25  ...    75           1              \n",
       "73   20lfg44aa002 NaN           SS  2  4.25  ...    73           1              \n",
       "..            ...  ..          ... ..   ...  ...   ...         ...    ...  ..   \n",
       "117  20lba50aa001 NaN  Alloy steel  3   9.5  ...   117           1              \n",
       "120  20lba70aa001 NaN  Alloy steel  3   9.5  ...   120           1              \n",
       "119  20lba60aa001 NaN  Alloy steel  3   9.5  ...   119           1              \n",
       "121  20lba80aa001 NaN  Alloy steel  3   9.5  ...   121           1              \n",
       "1    10lba60aa001 NaN  Alloy steel  3   9.5  ...     1           1              \n",
       "\n",
       "    DC GroupNC Dostup Pletter  F under containment  \n",
       "15           B     II       a                       \n",
       "77           B     II       a                       \n",
       "76           B     II       a                       \n",
       "75           B     II       a                       \n",
       "73           B     II       a                       \n",
       "..  ..     ...    ...     ... ..               ...  \n",
       "117          C    III       a                       \n",
       "120          C    III       a                       \n",
       "119          C    III       a                       \n",
       "121          C    III       a                       \n",
       "1            C    III       a                       \n",
       "\n",
       "[128 rows x 49 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_xls = pd.ExcelFile('Text_dict_ver.2.xlsx')\n",
    "\n",
    "text_Type = pd.read_excel(text_xls, 'text_Type').replace('\\s+', ' ', regex=True).astype(str)\n",
    "text_Type['Тригер'] = text_Type['Тригер'].apply(lambda x: x.lower())\n",
    "text_Time = pd.read_excel(text_xls, 'Text_Time').replace('\\s+', ' ', regex=True).astype(str)\n",
    "text_Time['Тригер'] = text_Time['Тригер'].apply(lambda x: x.lower())\n",
    "text_NC = pd.read_excel(text_xls, 'Text_NC').replace('\\s+', ' ', regex=True).astype(str)\n",
    "text_NC['Тригер'] = text_NC['Тригер'].apply(lambda x: x.lower())\n",
    "text_Kv = pd.read_excel(text_xls, 'Text_Kv').replace('\\s+', ' ', regex=True).astype(str)\n",
    "text_Kv['Тригер'] = text_Kv['Тригер'].apply(lambda x: x.lower())\n",
    "text_Gmin = pd.read_excel(text_xls, 'Text_Gmin').replace('\\s+', ' ', regex=True).astype(str)\n",
    "text_Gmin['Тригер'] = text_Gmin['Тригер'].apply(lambda x: x.lower())\n",
    "text_Gmax = pd.read_excel(text_xls, 'Text_Gmax').replace('\\s+', ' ', regex=True).astype(str)\n",
    "text_Gmax['Тригер'] = text_Gmax['Тригер'].apply(lambda x: x.lower())\n",
    "text_Fluid = pd.read_excel(text_xls, 'Text_Fluid').replace('\\s+', ' ', regex=True).astype(str)\n",
    "text_Fluid['Тригер'] = text_Fluid['Тригер'].apply(lambda x: x.lower())\n",
    "text_Gmax = pd.read_excel(text_xls, 'Text_Gmax').replace('\\s+', ' ', regex=True).astype(str)\n",
    "text_Gmax['Тригер'] = text_Gmax['Тригер'].apply(lambda x: x.lower())\n",
    "text_Connection_pipeline = pd.read_excel(text_xls, 'Text_Connection_pipeline').replace('\\s+', ' ', regex=True).astype(str)\n",
    "text_Connection_pipeline['Тригер'] = text_Connection_pipeline['Тригер'].apply(lambda x: x.lower())\n",
    "text_Actuator_type = pd.read_excel(text_xls, 'Text_Actuator_type').replace('\\s+', ' ', regex=True).astype(str)\n",
    "text_Actuator_type['Тригер'] = text_Actuator_type['Тригер'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_Type\n",
    "if 'Type' in spec.columns:\n",
    "    if not 'Bellow' in spec.columns:\n",
    "        spec['Bellow'] = ''\n",
    "    if not 'Actuator type' in spec.columns:\n",
    "        spec['Actuator type'] = ''\n",
    "    if not 'RPI' in spec.columns:\n",
    "        spec['RPI'] = ''\n",
    "    if not 'DC' in spec.columns:\n",
    "        spec['DC'] = ''\n",
    "    if not 'Fluid' in spec.columns:\n",
    "        spec['Fluid'] = ''\n",
    "    if not 'Connection' in spec.columns:\n",
    "        spec['Connection'] = ''\n",
    "    if not 'Material' in spec.columns:\n",
    "        spec['Material'] = ''\n",
    "    for index, item in spec['Type'].items():\n",
    "        \n",
    "        triggersInItem = text_Type.loc[text_Type['Тригер'].apply(lambda x: x in item)]\n",
    "        triggersInItem = triggersInItem.replace('nan','')\n",
    "        triggersInItem = triggersInItem.loc[~(triggersInItem['Weight']=='')]\n",
    "        triggersInItem['Weight'] = triggersInItem['Weight'].apply(lambda x: float(x))\n",
    "        valuesfForTypeField = ''\n",
    "        valuesForActuatorType = ''\n",
    "        valuesForBellow = ''\n",
    "        valuesForConnection = ''\n",
    "        valuesForMaterial = ''\n",
    "        valuesForRPI = ''\n",
    "        valuesForFluid = ''\n",
    "        valuesForDC = ''\n",
    "        weight = -1\n",
    "        \n",
    "        for i, val in triggersInItem.iterrows():\n",
    "                \n",
    "            if (valuesForBellow == '') & (val['Bellow'] != ''):\n",
    "                valuesForBellow = val['Bellow']\n",
    "                \n",
    "            if (valuesForRPI == '') & (val['RPI'] != ''):\n",
    "                valuesForRPI = val['RPI']\n",
    "                \n",
    "            if (valuesForDC == '') & (val['DC'] != ''):\n",
    "                valuesForDC = val['DC']\n",
    "            \n",
    "            if not val['Actuator type'] in valuesForActuatorType:\n",
    "                if weight == -1:\n",
    "                    valuesForActuatorType += val['Actuator type']\n",
    "                else:\n",
    "                    valuesForActuatorType += ', ' + val['Actuator type']\n",
    "                \n",
    "                \n",
    "            if not val['Connection'] in valuesForConnection:\n",
    "                if weight == -1 :\n",
    "                    valuesForConnection += val['Connection']\n",
    "                else:\n",
    "                    valuesForConnection += ', ' + val['Connection']\n",
    "                \n",
    "            if not val['Material'] in valuesForMaterial:\n",
    "                if weight == -1 :\n",
    "                    valuesForMaterial += val['Material']\n",
    "                else:\n",
    "                    valuesForMaterial += ', ' + val['Material']\n",
    "               \n",
    "            if not val['Fluid'] in valuesForFluid:\n",
    "                if weight == -1 :\n",
    "                    valuesForFluid += val['Fluid']\n",
    "                else:\n",
    "                    valuesForFluid += ', ' + val['Fluid']\n",
    "                    \n",
    "            if val['Weight'] >= weight:\n",
    "                if weight == -1:\n",
    "                    valuesfForTypeField += val['Type']\n",
    "                else:\n",
    "                    valuesfForTypeField += ', ' + val['Type']\n",
    "                weight = val['Weight']\n",
    "                \n",
    "        if valuesfForTypeField != '':\n",
    "            spec['Type'].loc[index] = valuesfForTypeField\n",
    "        spec['Bellow'].loc[index] = valuesForBellow\n",
    "        spec['RPI'].loc[index] = valuesForRPI\n",
    "        \n",
    "        if spec['DC'].loc[index] == '':\n",
    "            spec['DC'].loc[index] = valuesForDC\n",
    "        else:\n",
    "            if valuesForDC != '':\n",
    "                spec['DC'].loc[index] += ', ' + valuesForDC\n",
    "        \n",
    "        \n",
    "        if spec['Connection'].loc[index] == '':\n",
    "            spec['Connection'].loc[index] = valuesForConnection\n",
    "        else:\n",
    "            if valuesForConnection != '':\n",
    "                spec['Connection'].loc[index] += ', ' + valuesForConnection\n",
    "        \n",
    "        \n",
    "        if spec['Material'].loc[index] == '':\n",
    "            spec['Material'].loc[index] = valuesForMaterial\n",
    "        else:\n",
    "            if valuesForMaterial != '':\n",
    "                spec['Material'].loc[index] += ', ' + valuesForMaterial\n",
    "        \n",
    "        \n",
    "        if spec['Fluid'].loc[index] == '':\n",
    "            spec['Fluid'].loc[index] = valuesForFluid\n",
    "        else:\n",
    "            if valuesForFluid != '':\n",
    "                spec['Fluid'].loc[index] += ', ' + valuesForFluid\n",
    "        \n",
    "        \n",
    "        if spec['Actuator type'].loc[index] == '':\n",
    "            spec['Actuator type'].loc[index] = valuesForActuatorType\n",
    "        else:\n",
    "            if valuesForActuatorType != '':\n",
    "                spec['Actuator type'].loc[index] += ', ' + valuesForActuatorType\n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_Time\n",
    "if 'Time' in spec.columns:\n",
    "    for index, item in spec['Time'].items():\n",
    "        spec['Time'].loc[index] = re.sub(\"[^0-9]\", \"\", str(spec['Time'].loc[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text_NC\n",
    "if 'NC' in spec.columns:\n",
    "    if not 'GroupNC' in spec.columns:\n",
    "        spec['GroupNC'] = ''\n",
    "    if not 'Dostup' in spec.columns:\n",
    "        spec['Dostup'] = ''\n",
    "    if not 'Pletter' in spec.columns:\n",
    "        spec['Pletter'] = ''\n",
    "    if not 'SeismoCat' in spec.columns:\n",
    "        spec['SeismoCat'] = ''\n",
    "    for index, item in spec['NC'].items():\n",
    "        triggersInItem = text_NC.loc[text_NC['Тригер'].str.contains(item)]\n",
    "        triggersInItem = triggersInItem.replace('nan','')\n",
    "        triggersInItem['Weight'] = triggersInItem['Weight'].apply(lambda x: float(x))\n",
    "        NC_values = ''\n",
    "        GroupNC_values = ''\n",
    "        Dostup_values = ''\n",
    "        Pletter_values = ''\n",
    "        SeismoCat_values = ''\n",
    "        \n",
    "        # на случай предпоследнего варианта с весом 4000\n",
    "        if len(re.sub(\"[^0-9]\", \"\", item)) == len(item):\n",
    "            NC_values = item\n",
    "            continue\n",
    "        \n",
    "        # для основной массы \n",
    "        for i, val in triggersInItem.iterrows():\n",
    "            if NC_values == '':\n",
    "                NC_values = val['NC']\n",
    "            else:\n",
    "                NC_values += ', ' + val['NC']\n",
    "\n",
    "            if GroupNC_values == '':\n",
    "                GroupNC_values = val['GroupNC']\n",
    "            else:\n",
    "                GroupNC_values += ', ' + val['GroupNC']\n",
    "\n",
    "            if Dostup_NC == '':\n",
    "                Dostup_NC = val['Dostup']\n",
    "            else:\n",
    "                Dostup_NC += ', ' + val['Dostup']\n",
    "\n",
    "            if Pletter_values == '':\n",
    "                Pletter_values = val['Pletter']\n",
    "            else:\n",
    "                Pletter_values += ', ' + val['Pletter']\n",
    "\n",
    "            if SeismoCat_values == '':\n",
    "                SeismoCat_values = val['SeismoCat']\n",
    "            else:\n",
    "                SeismoCat_values += ', ' + val['SeismoCat']\n",
    "                \n",
    "        \n",
    "        # для последнего варианта с весом 4000\n",
    "        for el in re.findall(r'[0-9]+/[^0-9]+', item):\n",
    "            NC_values += ', ' + el\n",
    "            \n",
    "        # для вариантов с весом 3000\n",
    "        for el in re.findall(r'[^0-9], i', item):\n",
    "            if SeismoCat_values == '':\n",
    "                SeismoCat_values = '1'\n",
    "            else:\n",
    "                SeismoCat_values += ', 1'\n",
    "        \n",
    "        for el in re.findall(r'[^0-9], ii', item):\n",
    "            if SeismoCat_values == '':\n",
    "                SeismoCat_values = '2'\n",
    "            else:\n",
    "                SeismoCat_values += ', 2'\n",
    "        \n",
    "        for el in re.findall(r'[^0-9], iii', item):\n",
    "            if SeismoCat_values == '':\n",
    "                SeismoCat_values = '3'\n",
    "            else:\n",
    "                SeismoCat_values += ', 3'\n",
    "                \n",
    "        for el in re.findall(r'[^0-9]/i', item):\n",
    "            if SeismoCat_values == '':\n",
    "                SeismoCat_values = '1'\n",
    "            else:\n",
    "                SeismoCat_values += ', 1'\n",
    "        \n",
    "        for el in re.findall(r'[^0-9]/ii', item):\n",
    "            if SeismoCat_values == '':\n",
    "                SeismoCat_values = '2'\n",
    "            else:\n",
    "                SeismoCat_values += ', 2'\n",
    "        \n",
    "        for el in re.findall(r'[^0-9]/iii', item):\n",
    "            if SeismoCat_values == '':\n",
    "                SeismoCat_values = '3'\n",
    "            else:\n",
    "                SeismoCat_values += ', 3'\n",
    "        \n",
    "        if NC_values != '':\n",
    "            spec['NC'].loc[index] = NC_values\n",
    "                \n",
    "        if spec['GroupNC'].loc[index] == '':\n",
    "            spec['GroupNC'].loc[index] = GroupNC_values\n",
    "        else:\n",
    "            if GroupNC_values != '':\n",
    "                spec['GroupNC'].loc[index] += ', ' + GroupNC_values\n",
    "                \n",
    "        if spec['Dostup'].loc[index] == '':\n",
    "            spec['Dostup'].loc[index] = Dostup_values\n",
    "        else:\n",
    "            if Dostup_values != '':\n",
    "                spec['Dostup'].loc[index] += ', ' + Dostup_values\n",
    "                \n",
    "        if spec['Pletter'].loc[index] == '':\n",
    "            spec['Pletter'].loc[index] = Pletter_values\n",
    "        else:\n",
    "            if Pletter_values != '':\n",
    "                spec['Pletter'].loc[index] += ', ' + Pletter_values\n",
    "                \n",
    "        if spec['SeismoCat'].loc[index] == '':\n",
    "            spec['SeismoCat'].loc[index] = SeismoCat_values\n",
    "        else:\n",
    "            if SeismoCat_values != '':\n",
    "                spec['SeismoCat'].loc[index] += ', ' + SeismoCat_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_Kv\n",
    "if 'Kv' in spec.columns:\n",
    "    if not 'F' in spec.columns:\n",
    "        spec['F'] = ''\n",
    "    for index, item in spec['Kv'].items():\n",
    "        Kv_values = ''\n",
    "        F_values = ''\n",
    "        el = ''\n",
    "        \n",
    "        try:\n",
    "            el = re.findall(r'kv=[0-9]+ fmin=[0-9]+ см2', item)[0]\n",
    "            numbersFromElement = re.findall(r'[0-9]+',el)\n",
    "            Kv_values = numbersFromElement[0]\n",
    "            F_values = numbersFromElement[1]\n",
    "        except: \n",
    "            pass\n",
    "        \n",
    "        if len(re.sub(\"[^0-9]\", \"\", item)) == len(item):\n",
    "            Kv_values = item\n",
    "        \n",
    "        if Kv_values != '':\n",
    "            spec['Kv'].loc[index] = Kv_values\n",
    "            spec['F'].loc[index] = F_values\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_Gmin\n",
    "if 'Gmin under ∆Pmax' in spec.columns:\n",
    "    for index, item in spec['Gmin under ∆Pmax'].items():\n",
    "        Gmin_value = ''\n",
    "        el = ''\n",
    "        try:\n",
    "            el = re.findall(r'[0-9]+ нм3/ч', item)[0]\n",
    "            Gmin_value = re.findall(r'[0-9]+',el)[0]\n",
    "        except: pass\n",
    "        \n",
    "        if len(re.sub(\"[^0-9]\", \"\", item)) == len(item):\n",
    "            Gmin_value = item\n",
    "            \n",
    "        if Gmin_value != '':\n",
    "            spec['Gmin under ∆Pmax'].loc[index] = Gmin_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_Gmax\n",
    "if 'Gmax under ∆Pmin' in spec.columns:\n",
    "    for index, item in spec['Gmax under ∆Pmin'].items():\n",
    "        Gmax_value = ''\n",
    "        el = ''\n",
    "        try:\n",
    "            el = re.findall(r'[0-9]+ нм3/ч', item)[0]\n",
    "            Gmax_value = re.findall(r'[0-9]+',el)[0]\n",
    "        except: pass\n",
    "        \n",
    "        if len(re.sub(\"[^0-9]\", \"\", item)) == len(item):\n",
    "            Gmax_value = item\n",
    "            \n",
    "        if Gmax_value != '':\n",
    "            spec['Gmax under ∆Pmin'].loc[index] = Gmax_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_Fluid\n",
    "if 'Fluid' in spec.columns:\n",
    "    for index, item in spec['Fluid'].items():\n",
    "        triggersInItem = text_Fluid.loc[text_Fluid['Тригер'].str.contains(item)]\n",
    "        if len(triggersInItem) > 0:\n",
    "            spec['Fluid'].loc[index] = ', '.join(list(triggersInItem['Fluid'].astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text_Connection_pipeline\n",
    "if 'Connection_pipeline' in spec.columns:\n",
    "    for index, item in spec['Connection_pipeline'].items():\n",
    "        Connection_pipeline_value = ''\n",
    "        el = ''\n",
    "        try:\n",
    "            el = re.findall(r'[0-9]+x[0-9]+', item)[0]\n",
    "            Connection_pipeline_value = el\n",
    "        except: pass\n",
    "        \n",
    "            \n",
    "        if Connection_pipeline_value != '':\n",
    "            spec['Connection_pipeline'].loc[index] = Connection_pipeline_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_Actuator_type\n",
    "if 'Actuator type' in spec.columns:\n",
    "    if not 'RPI' in spec.columns:\n",
    "        spec['RPI'] = ''\n",
    "    if not 'under containment' in spec.columns:\n",
    "        spec['under containment'] = ''\n",
    "    for index, item in spec['Actuator type'].items():\n",
    "        Actuator_type_values = ''\n",
    "        RPI_values = ''\n",
    "        under_containment_values = ''\n",
    "        triggersInItem = text_Actuator_type.loc[text_Actuator_type['Тригер'].str.contains(item)]\n",
    "        triggersInItem = triggersInItem.replace('nan','')\n",
    "        triggersInItem['Weight'] = triggersInItem['Weight'].apply(lambda x: float(x))\n",
    "        \n",
    "        if len(triggersInItem) > 0:\n",
    "            triggersWithBigWeight = triggersInItem.loc[triggersInItem['Weight'] == triggersInItem['Weight'].iloc[0]]\n",
    "        else: continue\n",
    "        \n",
    "        Actuator_type_values = ', '.join(set(triggersWithBigWeight['Actuator type']))\n",
    "        \n",
    "        RPI_values = set(triggersInItem['RPI'])\n",
    "        RPI_values.discard('')\n",
    "        under_containment_values = set(triggersInItem['under containment'])\n",
    "        under_containment_values.discard('')\n",
    "        if Actuator_type_values != '':\n",
    "            spec['Actuator type'].loc[index] = Actuator_type_values\n",
    "            if len(under_containment_values) > 0:\n",
    "                under_containment_value = next(iter(under_containment_values))\n",
    "                spec['under containment'].loc[index] = under_containment_value\n",
    "            if len(RPI_values) > 0:\n",
    "                RPI_value = next(iter(RPI_values))\n",
    "                spec['RPI'].loc[index] = RPI_value\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['34x2']"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Труба 34x2'\n",
    "re.findall(r'[0-9]+x[0-9]+', 'Труба 34x2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15     BS\n",
       "77     BS\n",
       "76     BS\n",
       "75     BS\n",
       "73     BS\n",
       "       ..\n",
       "117    BS\n",
       "120    BS\n",
       "119    BS\n",
       "121    BS\n",
       "1      BS\n",
       "Name: Actuator type, Length: 128, dtype: object"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec['Actuator type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = set(['sfgs',''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "l.discard('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = pd.read_excel('specs/spec (129).xlsx').replace('\\s+', ' ', regex=True).astype(str).apply(lambda x: x.str.lower().replace('nan', np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>спецификация оборудования (материалов)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>спецификация 1.2 на поставку клапанов кос для ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>№ п/п</td>\n",
       "      <td>наименование</td>\n",
       "      <td>характеристика</td>\n",
       "      <td>ед. изм.</td>\n",
       "      <td>кол-во</td>\n",
       "      <td>стоимость ед. руб без ндс</td>\n",
       "      <td>стоимость ед. руб с ндс</td>\n",
       "      <td>стоимость всего. руб без ндс</td>\n",
       "      <td>стоимость всего. руб с ндс</td>\n",
       "      <td>изготовитель</td>\n",
       "      <td>срок поставки</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.</td>\n",
       "      <td>клапан обратный с сервоприводом кос-300 ду300</td>\n",
       "      <td>dn 300; pn 29,1 кгс/см2; т 232 с. материал кор...</td>\n",
       "      <td>шт.</td>\n",
       "      <td>4</td>\n",
       "      <td>8972750</td>\n",
       "      <td>10587845</td>\n",
       "      <td>35891000</td>\n",
       "      <td>42351380</td>\n",
       "      <td>ringo valvulas s.l. испания</td>\n",
       "      <td>не позднее 30.09.2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.</td>\n",
       "      <td>клапан обратный с сервоприводом кос-400 ду400</td>\n",
       "      <td>dn 400; pn 18,45 кгс/см2; т 210 с. материал ко...</td>\n",
       "      <td>шт.</td>\n",
       "      <td>6</td>\n",
       "      <td>9540200</td>\n",
       "      <td>11257436</td>\n",
       "      <td>57241200</td>\n",
       "      <td>67544616</td>\n",
       "      <td>ringo valvulas s.l. испания</td>\n",
       "      <td>не позднее 30.09.2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.</td>\n",
       "      <td>клапан обратный с сервоприводом кос-600 ду600</td>\n",
       "      <td>dn 600; pn 5,06 кгс/см2; т 158,5 с. материал к...</td>\n",
       "      <td>шт.</td>\n",
       "      <td>2</td>\n",
       "      <td>13165950</td>\n",
       "      <td>15535821</td>\n",
       "      <td>26331900</td>\n",
       "      <td>31071642</td>\n",
       "      <td>ringo valvulas s.l. испания</td>\n",
       "      <td>не позднее 30.09.2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.</td>\n",
       "      <td>клапан обратный с сервоприводом кос-800 ду800</td>\n",
       "      <td>dn 800; pn 11,5 кгс/см2; т 188,9 с. материал к...</td>\n",
       "      <td>шт.</td>\n",
       "      <td>4</td>\n",
       "      <td>16306800</td>\n",
       "      <td>19242024</td>\n",
       "      <td>65227200</td>\n",
       "      <td>76968096</td>\n",
       "      <td>ringo valvulas s.l. испания</td>\n",
       "      <td>не позднее 30.09.2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>217935734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>от поставщика:</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>________________ /_______________/</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>м.п.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         Unnamed: 1  \\\n",
       "0         NaN                                                NaN   \n",
       "1         NaN  спецификация 1.2 на поставку клапанов кос для ...   \n",
       "2       № п/п                                       наименование   \n",
       "3          1.      клапан обратный с сервоприводом кос-300 ду300   \n",
       "4          2.      клапан обратный с сервоприводом кос-400 ду400   \n",
       "5          3.      клапан обратный с сервоприводом кос-600 ду600   \n",
       "6          4.      клапан обратный с сервоприводом кос-800 ду800   \n",
       "7         NaN                                                NaN   \n",
       "8         NaN                                                NaN   \n",
       "9         NaN                                                NaN   \n",
       "10        NaN                                                NaN   \n",
       "11        NaN                                                NaN   \n",
       "12        NaN                                                NaN   \n",
       "13        NaN                                                NaN   \n",
       "14        NaN                                                NaN   \n",
       "\n",
       "                                           Unnamed: 2 Unnamed: 3 Unnamed: 4  \\\n",
       "0                                                 NaN        NaN        NaN   \n",
       "1                                                 NaN        NaN        NaN   \n",
       "2                                      характеристика   ед. изм.     кол-во   \n",
       "3   dn 300; pn 29,1 кгс/см2; т 232 с. материал кор...        шт.          4   \n",
       "4   dn 400; pn 18,45 кгс/см2; т 210 с. материал ко...        шт.          6   \n",
       "5   dn 600; pn 5,06 кгс/см2; т 158,5 с. материал к...        шт.          2   \n",
       "6   dn 800; pn 11,5 кгс/см2; т 188,9 с. материал к...        шт.          4   \n",
       "7                                                 NaN        NaN        NaN   \n",
       "8                                                 NaN        NaN        NaN   \n",
       "9                                                 NaN        NaN        NaN   \n",
       "10                                                NaN        NaN        NaN   \n",
       "11                                                NaN        NaN        NaN   \n",
       "12                                                NaN        NaN        NaN   \n",
       "13                                                NaN        NaN        NaN   \n",
       "14                                                NaN        NaN        NaN   \n",
       "\n",
       "                                Unnamed: 5               Unnamed: 6  \\\n",
       "0   спецификация оборудования (материалов)                      NaN   \n",
       "1                                      NaN                      NaN   \n",
       "2                стоимость ед. руб без ндс  стоимость ед. руб с ндс   \n",
       "3                                  8972750                 10587845   \n",
       "4                                  9540200                 11257436   \n",
       "5                                 13165950                 15535821   \n",
       "6                                 16306800                 19242024   \n",
       "7                                      NaN                      NaN   \n",
       "8                                      NaN                      NaN   \n",
       "9                                      NaN                      NaN   \n",
       "10                                     NaN                      NaN   \n",
       "11                                     NaN                      NaN   \n",
       "12                                     NaN                      NaN   \n",
       "13                                     NaN                      NaN   \n",
       "14                                     NaN                      NaN   \n",
       "\n",
       "                      Unnamed: 7                  Unnamed: 8  \\\n",
       "0                            NaN                         NaN   \n",
       "1                            NaN                         NaN   \n",
       "2   стоимость всего. руб без ндс  стоимость всего. руб с ндс   \n",
       "3                       35891000                    42351380   \n",
       "4                       57241200                    67544616   \n",
       "5                       26331900                    31071642   \n",
       "6                       65227200                    76968096   \n",
       "7                            NaN                   217935734   \n",
       "8                            NaN                         NaN   \n",
       "9                            NaN                         NaN   \n",
       "10                           NaN                         NaN   \n",
       "11                           NaN                         NaN   \n",
       "12                           NaN                         NaN   \n",
       "13                           NaN                         NaN   \n",
       "14                           NaN                         NaN   \n",
       "\n",
       "                            Unnamed: 9            Unnamed: 10  \n",
       "0                                  NaN                    NaN  \n",
       "1                                  NaN                    NaN  \n",
       "2                         изготовитель          срок поставки  \n",
       "3          ringo valvulas s.l. испания  не позднее 30.09.2018  \n",
       "4          ringo valvulas s.l. испания  не позднее 30.09.2018  \n",
       "5          ringo valvulas s.l. испания  не позднее 30.09.2018  \n",
       "6          ringo valvulas s.l. испания  не позднее 30.09.2018  \n",
       "7                                  NaN                    NaN  \n",
       "8                                  NaN                    NaN  \n",
       "9                                  NaN                    NaN  \n",
       "10                                 NaN                    NaN  \n",
       "11                      от поставщика:                    NaN  \n",
       "12                                 NaN                    NaN  \n",
       "13  ________________ /_______________/                    NaN  \n",
       "14                                м.п.                    NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sls_env",
   "language": "python",
   "name": "sls_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
